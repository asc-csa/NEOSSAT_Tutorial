{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8e077f",
   "metadata": {},
   "source": [
    "# Tutoriel NEOSSat - Traitement et Analytique\n",
    "\n",
    "**Tutoriel** : Ce tutoriel démontre comment télécharger et charger des fichiers FITS de CADC, effectuer un traitement sommaire d'imagerie, et l'analyse de striures et de mouvement d'objets en Python.<br>\n",
    "\n",
    "Ce tutoriel utilise des données d'imagerie de la mission NEOSSat.<br>\n",
    "\n",
    "**Mission et Instrument** : [NEOSSat](https://www.asc-csa.gc.ca/eng/satellites/neossat/) <br>\n",
    "\n",
    "**Objectifs de la Mission** :\n",
    "* Connaissance de la situation spatiale : Objets géocroiseurs (astéroïdes, débris spatiaux)\n",
    "* Cible astronomique : objets célestes (comètes, nébuleuses, galaxies, exoplanètes)\n",
    "\n",
    "**Exigences du système** : Python 3.9+ (testé)<br>\n",
    "\n",
    "**Niveau du tutoriel** : Intermédiaire <br>\n",
    "\n",
    "***\n",
    "**Licence MIT** <br>\n",
    "Copyright (c) Sa Majesté le Roi du chef du Canada, représentée par l'Agence spatiale canadienne, 2024. <br>\n",
    "Droit d'auteur (c) Sa Majesté le Roi du chef du Canada, représentée par l'Agence Spatiale Canadienne, 2024.<br>\n",
    "\n",
    "Pour plus d'informations, veuillez vous référer au fichier *License.txt*.\n",
    "\n",
    "***\n",
    "**Informations contextuelles** <br>\n",
    "La mission [NEOSSat](https://www.asc-csa.gc.ca/eng/satellites/neossat/) lancée le 25 février 2013, est le premier télescope spatial au monde dédié à la détection et au suivi d'objets géocroiseurs.\n",
    "\n",
    "Dans le cadre des efforts du Canada pour observer et suivre les astéroïdes, comètes, satellites et débris spatiaux, ce microsatellite, seulement de la taille d'une valise, est une plateforme d'observation puissante.\n",
    "\n",
    "Opérant à une altitude d'environ 800 kilomètres, ce microsatellite orbite la Terre toutes les 100 minutes et fournit une surveillance continue des objets géocroiseurs. NEOSSat utilise une technologie avancée de roue de réaction, d'abord démontrée par le satellite [Microvariabilité et Oscillations des Étoiles (MOST)](https://www.asc-csa.gc.ca/eng/satellites/most/) lui permettant de balayer des régions de l'espace près du Soleil, aidant à identifier les astéroïdes et comètes qui peuvent passer près de la Terre.\n",
    "\n",
    "Dans le cadre de l'engagement du Canada envers la sécurité spatiale, NEOSSat est impliqué dans le suivi des débris spatiaux, fournissant des données essentielles sur les objets qui sont difficiles à observer par les télescopes terrestres. La mission est financée conjointement par l'Agence spatiale canadienne (ASC) et Recherche et développement pour la défense Canada (RDDC). NEOSSat continue à faire progresser le rôle du Canada dans l'exploration spatiale et la sécurité grâce à ses contributions continues au suivi d'astéroïdes, à la surveillance de débris spatiaux, et à la recherche d'exoplanètes.\n",
    "\n",
    "***\n",
    "**Lecture complémentaire** <br>\n",
    "* **Titre :** [Guide de l'utilisateur d'image FITS NEOSSat](https://data.asc-csa.gc.ca/users/OpenData_DonneesOuvertes/pub/NEOSSAT/Supporting%20Documents/CSA-NEOSSAT-MAN-0002_FITS_IMAGE_UGUIDE-v4-00.pdf)\n",
    "    * **Description :** Un document précieux qui contient des informations complètes et détaillées concernant le format FITS de NEOSSat, la sémantique des mots-clés, et les données disponibles dans le fichier FITS.\n",
    "<p></p>\n",
    "\n",
    "* **Titre :** [L'Expérience NEOSSat : 5 ans dans la vie du télescope de surveillance spatiale du Canada](https://data.asc-csa.gc.ca/users/OpenData_DonneesOuvertes/pub/NEOSSAT/Supporting%20Documents/NEOSSat%20Experience-v1.5.pdf)\n",
    "    * **Description :** Un papier de résumé utile concernant les développements, défis et succès du programme NEOSSat.\n",
    "<p></p>\n",
    "\n",
    "* **Titre :** [Principales découvertes de la mission de microsatellite SSA spatial NEOSSat](https://cradpdf.drdc-rddc.gc.ca/PDFS/unc326/p808033_A1b.pdf)\n",
    "    * **Description :** Un autre papier de résumé utile concernant les développements, défis et succès du programme NEOSSat.\n",
    "<p></p>\n",
    "\n",
    "* **Titre :** [Surveillance spatiale depuis un microsatellite : Traitement d'observation métrique de NEOSSat](https://espace.rmc.ca/jspui/handle/11264/1364)\n",
    "    * **Description :** Une thèse concernant la surveillance géocroiseur en utilisant NEOSSat, incluant des informations de traitement approfondies et le développement d'algorithmes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a70616",
   "metadata": {},
   "source": [
    "## Bibliothèques Requises\n",
    "* Ci-dessous, nous initialiserons plusieurs bibliothèques requises pour le tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b05324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astroquery.cadc import Cadc\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.morphology import (\n",
    "    binary_closing,\n",
    "    binary_opening,\n",
    "    remove_small_objects,\n",
    "    binary_dilation,\n",
    "    disk,\n",
    ")\n",
    "from skimage.draw import line as draw_line\n",
    "from pylsd.lsd import lsd\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a33971",
   "metadata": {},
   "source": [
    "## Section A - Acquisition d'imagerie NEOSSat\n",
    "* Information sur le Portail de Données Ouvertes\n",
    "* Information sur le Centre canadien de données astronomiques\n",
    "* Recherche, filtrage et téléchargement d'imagerie NEOSSat\n",
    "\n",
    "Pour acquérir des images NEOSSat, vous pouvez accéder aux données de deux sources principales : le Portail de Données Ouvertes de l'Agence spatiale canadienne (ASC) et le Centre canadien de données astronomiques (CADC).\n",
    "\n",
    "L'ASC offre les données NEOSSat à travers son [Portail de Données Ouvertes](https://open.canada.ca/data/en/dataset/9ae3e718-8b6d-40b7-8aa4-858f00e84b30), aux côtés d'autres ressources utiles. Ces données peuvent ensuite être téléchargées manuellement ou à travers le Protocole de Transfert de Fichiers (FTP), et sont principalement organisées par date et heure. Pour des informations supplémentaires sur l'accès via FTP, veuillez voir le [tutoriel](https://github.com/asc-csa/NEOSSAT_Tutorial/blob/main/01_%20Extracting%20Data%20and%20Visualization.ipynb) suivant.\n",
    "\n",
    "Alternativement, le [CADC](https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/neossat/) fournit les données NEOSSat avec des capacités de recherche avancées, incluant date-heure, objet cible, paramètres d'acquisition et plus. Ces données peuvent être recherchées en utilisant leur [plateforme](https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/search/?collection=NEOSSAT&noexec=true), ou vous pouvez y accéder à travers [astroquery](https://astroquery.readthedocs.io/en/latest/) une bibliothèque Python populaire pour interroger et accéder aux données astronomiques. CADC fournit plusieurs [tutoriels](https://github.com/opencadc/notebook-tutorials/blob/master/astroquery_example_kbos.ipynb) utiles pour aider à mieux comprendre l'intégration d'astroquery avec CADC. Nous nous concentrerons sur l'utilisation d'astroquery pour télécharger et accéder aux données dans ce tutoriel.\n",
    "\n",
    "D'abord, en utilisant le [Langage de Requête de Données Astronomiques](https://www.ivoa.net/documents/ADQL/20180112/PR-ADQL-2.1-20180112.html) nous développerons une fonction pour créer des requêtes à utiliser dans astroquery. ADQL est un langage similaire au SQL permettant une recherche structurée des bases de données astronomiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e323b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_adql_query(start_date, end_date, collection='NEOSSAT', calibration_level='2'):\n",
    "\n",
    "    start_mjd = Time(start_date).mjd\n",
    "    end_mjd = Time(end_date).mjd\n",
    "\n",
    "    # Construct the ADQL query\n",
    "    adql_query = f\"\"\"\n",
    "    SELECT * FROM caom2.Plane AS Plane\n",
    "    JOIN caom2.Observation AS Observation ON Plane.obsID = Observation.obsID\n",
    "    WHERE (\n",
    "        INTERSECTS(\n",
    "            INTERVAL({start_mjd}, {end_mjd}),\n",
    "            Plane.time_bounds_samples\n",
    "        ) = 1\n",
    "        AND Observation.collection = '{collection}'\n",
    "        AND Plane.calibrationLevel = '{calibration_level}'\n",
    "        AND (\n",
    "            Plane.quality_flag IS NULL OR Plane.quality_flag != 'junk'\n",
    "        )\n",
    "    )\n",
    "    \"\"\"\n",
    "    return adql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_neossat_data_with_adql(adql_query):\n",
    "    # Execute the query using exec_sync\n",
    "    cadc = Cadc()\n",
    "    results = cadc.exec_sync(adql_query) \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e73bb",
   "metadata": {},
   "source": [
    "Pour fournir une facilité d'accès, nous avons combiné les fonctions ci-dessus en une fonction de recherche par date-heure ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_neossat_data(start_date, end_date):\n",
    "    # Convert start_date and end_date to MJD (Modified Julian Date)\n",
    "    start_mjd = Time(start_date).mjd\n",
    "    end_mjd = Time(end_date).mjd\n",
    "\n",
    "    # Construct the ADQL query\n",
    "    adql_query = f\"\"\"\n",
    "    SELECT * FROM caom2.Plane AS Plane\n",
    "    JOIN caom2.Observation AS Observation ON Plane.obsID = Observation.obsID\n",
    "    WHERE (\n",
    "        INTERSECTS(\n",
    "            INTERVAL({start_mjd}, {end_mjd}),\n",
    "            Plane.time_bounds_samples\n",
    "        ) = 1\n",
    "        AND Observation.collection = 'NEOSSAT'\n",
    "        AND Plane.calibrationLevel = '2'\n",
    "        AND (\n",
    "            Plane.quality_flag IS NULL OR Plane.quality_flag != 'junk'\n",
    "        )\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query using exec_sync\n",
    "    cadc = Cadc()\n",
    "    results = cadc.exec_sync(adql_query)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range for your search in the yyyy-mm-dd format\n",
    "start_date = '2023-12-05' \n",
    "end_date = '2023-12-06'\n",
    "\n",
    "# Search for NEOSSat data within the date range\n",
    "results_table = search_neossat_data(start_date, end_date)\n",
    "print(f\"Number of matching observations: {len(results_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154c32",
   "metadata": {},
   "source": [
    "Les résultats incluront des informations telles que les temps d'exposition, les heures de début d'observation, et les propriétés du filtre. Vous pouvez filtrer les données davantage selon vos besoins en utilisant ces champs dans la table retournée. Les filtres typiques peuvent inclure le nom de l'objet, les mots-clés d'instrument, ou le temps d'exposition. Quelques propriétés utiles incluent :\n",
    "\n",
    "* **productID**\n",
    "    * Les paramètres incluent cor, cord, clean et autres pour sélectionner le niveau de traitement appliqué (couvert en détail plus tard).\n",
    "* **instrument_keywords**\n",
    "    * 06-ST_ACQUIRE : Suivi général des cibles célestes.\n",
    "    * 16-FINE_POINT : Suivi précis des cibles célestes en mouvement rapide.\n",
    "* **type**\n",
    "    * Image d'objet ou sombre.\n",
    "* **target_name**\n",
    "    * Nom de la cible céleste suivie.\n",
    "* **time_exposure**\n",
    "    * Temps pendant lequel l'obturateur était ouvert et le capteur exposé, ce qui correspond au temps d'imagerie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, perform additional filtering of results based on additional criteria\n",
    "# For example, only select observations with exposure time greater than 105 seconds and using fine-point tracking \n",
    "results_table = results_table[(results_table['instrument_keywords'] == '16-FINE_POINT') & (results_table['time_exposure'] > 105)]\n",
    "\n",
    "# Taking only the first five records\n",
    "filtered_results = results_table[:5]\n",
    "\n",
    "# Displaying the first result\n",
    "filtered_results[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869880d",
   "metadata": {},
   "source": [
    "### Téléchargement de fichiers FITS NEOSSat\n",
    "\n",
    "Pour télécharger les données NEOSSat de CADC, nous utiliserons astroquery.cadc.Cadc pour interroger directement CADC.\n",
    "\n",
    "Le processus de téléchargement peut prendre du temps selon le nombre d'images et les vitesses de réseau. Pour éviter de retélécharger des fichiers, assurez-vous de les garder organisés dans un dossier désigné sur votre ordinateur. Vous pouvez spécifier le nom du dossier pendant le processus de téléchargement comme montré dans le code ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_neossat_data(results_table, folder_name='neossat_data'):\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    output_folder = os.path.join(current_dir, folder_name)\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cadc = Cadc()\n",
    "\n",
    "    # Get a list of data URLs based on the results table\n",
    "    data_urls = cadc.get_data_urls(results_table)\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    for url in data_urls:\n",
    "        # Extract the filename from the URL\n",
    "        filename = os.path.basename(url.split('?')[0])\n",
    "        filepath = os.path.join(output_folder, filename)\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            filenames.append(filepath)\n",
    "            print(f\"Downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {url}\")\n",
    "\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data to a local folder\n",
    "output_folder = 'neossat_example_data'\n",
    "downloaded_files = download_neossat_data(filtered_results, output_folder)\n",
    "print(f\"Downloaded {len(downloaded_files)} files to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa821017",
   "metadata": {},
   "source": [
    "## Section B - Visualisation et Exploration Initiales\n",
    "* Exploration initiale des données\n",
    "* Accès aux images\n",
    "\n",
    "Lors du travail avec les images FITS NEOSSat, il est important de comprendre la structure des fichiers FITS. Les images NEOSSat utilisent le format [FITS (Système de Transport d'Image Flexible)](https://fits.gsfc.nasa.gov/fits_primer.html), qui contient un en-tête principal et des extensions optionnelles avec des métadonnées comme les données de télémétrie brutes. Chaque image FITS de NEOSSat est typiquement une matrice de pixels 1024x1024, avec chaque pixel correspondant à environ 3 secondes d'arc dans le champ de vision. Les fichiers FITS NEOSSat incluent aussi des métadonnées telles que le temps d'exposition, le filtre, le pointage du télescope, et les paramètres de lecture CCD. Ces fichiers peuvent être ouverts et explorés en utilisant des bibliothèques Python comme astropy ou autres bibliothèques de visualisation d'images.\n",
    "\n",
    "Les images NEOSSat suivent aussi une convention de nommage stricte basée sur le niveau de traitement et le type d'image. Les noms de fichiers incluent des indicateurs pour les images brutes ou nettoyées, le temps d'acquisition et le type d'instrument.\n",
    "\n",
    "**Par exemple :**\n",
    "* NEOS_\"detector\"_\"timestamp\".fits\n",
    "    * Où \"detector\" est soit \"SCI\" (pour CCD Science) ou \"ST\" (pour CCD Star Tracker) et où\n",
    "    \"timestamp\" suit la convention \"YYYYDDDhhmmss\" correspondant au début d'exposition en\n",
    "    Temps Universel Coordonné (UTC).\n",
    "    * Les images nettoyées auront le suffixe _cor.fits pour les images nettoyées Python, et _clean.fits pour les images nettoyées Java.\n",
    "    * Les images nettoyées avec soustraction d'image sombre auront le suffixe _cord.fits.\n",
    "\n",
    "Plus de détails sur les conventions de nommage et la liste complète d'en-tête sont disponibles dans le [Guide de l'utilisateur d'image FITS](https://data.asc-csa.gc.ca/users/OpenData_DonneesOuvertes/pub/NEOSSAT/Supporting%20Documents/CSA-NEOSSAT-MAN-0002_FITS_IMAGE_UGUIDE-v4-00.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd79cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fits_data(filename):\n",
    "    data = fits.getdata(filename)\n",
    "    data = data.astype(np.float64)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_file = 'neossat_example_data/NEOS_SCI_2023339134953_cor.fits'  # Replace with the path to your FITS file\n",
    "example_image = read_fits_data(fits_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c57eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "vmin, vmax = np.percentile(example_image, [5, 95])\n",
    "plt.imshow(example_image, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "plt.title('Example Image')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the fits file header \n",
    "hdul = fits.open(fits_file)\n",
    "\n",
    "# Print the header of the primary HDU (Header Data Unit)\n",
    "print(hdul[0].header[:5])\n",
    "\n",
    "# Close the FITS file after processing\n",
    "hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e746f6a",
   "metadata": {},
   "source": [
    "## Section C - Prétraitement d'Images\n",
    "* Application de la correction d'overscan grossière\n",
    "* Processus pour développer les images sombres\n",
    "\n",
    "Avant d'analyser les images FITS NEOSSat, vous pourriez avoir besoin d'effectuer plusieurs étapes de prétraitement si les images ne contiennent pas de suffixe _cor, _cord ou _clean.\n",
    "\n",
    "Ces étapes et d'autres aident à s'assurer que les données d'image sont propres et libres d'artefacts et de [pixels chauds](https://www.astropy.org/ccd-reduction-and-photometry-guide/v/dev/notebooks/08-01-Identifying-hot-pixels.html). Une étape commune est la correction d'overscan, qui supprime les valeurs de pixels supplémentaires en dehors de la zone CCD qui ne correspondent pas aux données d'image réelles. De plus, la soustraction de trame sombre et la correction de champ plat sont typiquement nécessaires pour tenir compte du bruit et des variations de sensibilité des pixels à travers le détecteur.\n",
    "\n",
    "Pour un prétraitement avancé et une analyse d'image, il est hautement recommandé d'explorer la [Bibliothèque NEOSSat](https://github.com/jasonfrowe/neossat/tree/master) développée par Jason Rowe. L'utilisation d'exemple de la bibliothèque est disponible [ici](https://github.com/jasonfrowe/neossat/blob/master/notebooks/Cleaning%20NEOSSat%20Photometry.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_dimensions(filename, overscan_width=50):\n",
    "    header = fits.getheader(filename)\n",
    "    x_size = header['NAXIS1']\n",
    "    y_size = header['NAXIS2']\n",
    "    overscan_start_col = x_size - overscan_width\n",
    "    return x_size, y_size, overscan_start_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overscan_correction(science_data, overscan_region):\n",
    "    overscan_median = np.median(overscan_region, axis=1)\n",
    "    corrected_data = science_data - overscan_median[:, np.newaxis]\n",
    "    return corrected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1597d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_dark(dark_frames_directory):\n",
    "    dark_files = [f for f in os.listdir(dark_frames_directory) if f.endswith('.fits')]\n",
    "    dark_data_list = []\n",
    "\n",
    "    for filename in tqdm(dark_files, desc='Processing dark frames'):\n",
    "        input_path = os.path.join(dark_frames_directory, filename)\n",
    "        data = read_fits_data(input_path)\n",
    "        x_size, y_size, overscan_start_col = get_image_dimensions(input_path)\n",
    "        science_data = data[:, :overscan_start_col]\n",
    "        overscan_region = data[:, overscan_start_col:]\n",
    "        corrected_dark = overscan_correction(science_data, overscan_region)\n",
    "        dark_data_list.append(corrected_dark)\n",
    "\n",
    "    # Stack dark frames using median to reduce noise and reject outliers\n",
    "    dark_stack = np.array(dark_data_list)\n",
    "    master_dark = np.median(dark_stack, axis=0)\n",
    "    return master_dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a938cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dark_correction(overscan_corrected_directory, master_dark, output_directory):\n",
    "    cor_files = [f for f in os.listdir(overscan_corrected_directory) if f.endswith('_cor.fits')]\n",
    "\n",
    "    for filename in tqdm(cor_files, desc='Applying dark correction'):\n",
    "        input_path = os.path.join(overscan_corrected_directory, filename)\n",
    "\n",
    "        # Modify the output filename to include '_cord'\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        new_filename = base_filename.replace('_cor', '_cord') + '.fits'\n",
    "        output_path = os.path.join(output_directory, new_filename)\n",
    "\n",
    "        # Read the overscan-corrected data\n",
    "        data = read_fits_data(input_path)\n",
    "\n",
    "        # Ensure data and master_dark have the same shape\n",
    "        if data.shape != master_dark.shape:\n",
    "            print(f\"Warning: Shape mismatch between data {data.shape} and master dark {master_dark.shape}\")\n",
    "            # Crop or pad as necessary (here we crop to the smallest shape)\n",
    "            min_rows = min(data.shape[0], master_dark.shape[0])\n",
    "            min_cols = min(data.shape[1], master_dark.shape[1])\n",
    "            data = data[:min_rows, :min_cols]\n",
    "            master_dark_cropped = master_dark[:min_rows, :min_cols]\n",
    "        else:\n",
    "            master_dark_cropped = master_dark\n",
    "\n",
    "        # Subtract master dark\n",
    "        dark_corrected_data = data - master_dark_cropped\n",
    "\n",
    "        # Save the dark-corrected image\n",
    "        header = fits.getheader(input_path)\n",
    "        header.add_history('Dark correction applied.')\n",
    "        hdu = fits.PrimaryHDU(dark_corrected_data, header=header)\n",
    "        hdu.writeto(output_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories; they will use your current working directory\n",
    "input_directory = 'neossat_example_data' # Replace with your raw images directory\n",
    "output_directory = 'neossat_example_results'  # Replace with your processed images directory\n",
    "dark_frames_directory = 'dark_test'     # Replace with your dark frames directory\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List FITS files\n",
    "fits_files = [f for f in os.listdir(input_directory) if f.endswith('.fits')]\n",
    "\n",
    "# Overscan correction\n",
    "print(\"Starting overscan correction...\")\n",
    "for filename in tqdm(fits_files, desc='Processing images'):\n",
    "    input_path = os.path.join(input_directory, filename)\n",
    "\n",
    "    # Modify the output filename to include '_cor' before the extension\n",
    "    base_filename = os.path.splitext(filename)[0]\n",
    "    new_filename = base_filename + '_cor.fits'\n",
    "    output_path = os.path.join(output_directory, new_filename)\n",
    "\n",
    "    # Read the image data\n",
    "    data = read_fits_data(input_path)\n",
    "    x_size, y_size, overscan_start_col = get_image_dimensions(input_path)\n",
    "    science_data = data[:, :overscan_start_col]\n",
    "    overscan_region = data[:, overscan_start_col:]\n",
    "    corrected_data = overscan_correction(science_data, overscan_region)\n",
    "\n",
    "    # Save the corrected image\n",
    "    header = fits.getheader(input_path)\n",
    "    header.add_history('Overscan correction applied.')\n",
    "    hdu = fits.PrimaryHDU(corrected_data, header=header)\n",
    "    hdu.writeto(output_path, overwrite=True)\n",
    "print(\"Overscan correction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e89dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master dark frame\n",
    "print(\"Creating master dark frame...\")\n",
    "master_dark = create_master_dark(dark_frames_directory)\n",
    "master_dark_path = os.path.join(output_directory, 'master_dark.fits')\n",
    "hdu = fits.PrimaryHDU(master_dark)\n",
    "hdu.writeto(master_dark_path, overwrite=True)\n",
    "print(\"Master dark frame created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dark correction to overscan-corrected images\n",
    "print(\"Applying dark correction...\")\n",
    "apply_dark_correction(output_directory, master_dark, output_directory)\n",
    "print(\"Dark correction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdcfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image type ('_cor' for overscan-corrected, '_cord' for dark-corrected, or '_clean' for alternative overscan-corrected)\n",
    "image_type = '_cord'\n",
    "\n",
    "# List images of the specified type\n",
    "image_files = [f for f in os.listdir(output_directory) if f.endswith(f'{image_type}.fits')]\n",
    "image_files.sort()  # Sort the list for consistency\n",
    "\n",
    "print(f\"Found {len(image_files)} images of type {image_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516aded7",
   "metadata": {},
   "source": [
    "Ensuite, nous appliquerons l'empilement d'images, une technique commune en traitement d'image pour réduire le bruit de fond et améliorer la qualité globale d'image. L'empilement de plusieurs images brutes résulte en une image finale avec une clarté significativement meilleure que n'importe quelle image brute unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eceba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_images(image_files, image_directory):\n",
    "    image_data_list = []\n",
    "    for filename in tqdm(image_files, desc='Reading images'):\n",
    "        filepath = os.path.join(image_directory, filename)\n",
    "        data = read_fits_data(filepath)\n",
    "        image_data_list.append(data)\n",
    "    \n",
    "    image_shape = image_data_list[0].shape\n",
    "    stacked_image = np.median(np.array(image_data_list), axis=0)\n",
    "    return stacked_image, image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1965128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the images\n",
    "print('Stacking images...')\n",
    "stacked_image, image_shape = stack_images(image_files, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f137c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stacked image\n",
    "stacked_image_path = os.path.join(output_directory, f'stacked_image{image_type}.fits')\n",
    "hdu = fits.PrimaryHDU(stacked_image)\n",
    "hdu.writeto(stacked_image_path, overwrite=True)\n",
    "print(f'Stacked image saved to {stacked_image_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32db8ed",
   "metadata": {},
   "source": [
    "## Section D - Analyse d'Image et Détection\n",
    "* Détection de segments de ligne pour détecter les striures\n",
    "* Détection de mouvement pour détecter les objets géocroiseurs\n",
    "\n",
    "Cette section vous guidera à travers le processus d'analyse d'imagerie NEOSSat, se concentrant sur la détection de striures de mouvement dans les trames d'image. Les images haute résolution de NEOSSat sont idéales pour détecter des objets faibles, et le mode de suivi d'étoile fournit des informations supplémentaires sur le mouvement d'objet relatif au champ d'étoile. La détection d'objets en mouvement peut être particulièrement importante pour identifier des objets géocroiseurs (NEO) ou des débris spatiaux.\n",
    "\n",
    "Une des premières étapes pour détecter des objets dans des images astronomiques est d'appliquer la détection de contour pour mettre en évidence les objets potentiels d'intérêt. Le [LSD : Détecteur de Segment de Ligne](http://www.ipol.im/pub/art/2012/gjmr-lsd/) est particulièrement utile dans ce cas, car il peut efficacement identifier les limites même dans des images bruyantes comme celles capturées dans des environnements spatiaux. La documentation supplémentaire sur l'implémentation de cet algorithme en Python est disponible [ici](https://github.com/primetang/pylsd?tab=readme-ov-file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_streaklets(image_data):\n",
    "    # Preprocess the image\n",
    "    smoothed = gaussian_filter(image_data, sigma=1)\n",
    "    normalized = (smoothed - np.min(smoothed)) / (np.max(smoothed) - np.min(smoothed))\n",
    "    img_uint8 = (normalized * 255).astype(np.uint8)\n",
    "\n",
    "    # Apply LSD\n",
    "    lines = lsd(img_uint8)\n",
    "\n",
    "    # Create an empty mask\n",
    "    streaklet_mask = np.zeros_like(img_uint8, dtype=bool)\n",
    "\n",
    "    # Define minimum length for line segments\n",
    "    min_length = 10  # Adjust as needed\n",
    "\n",
    "    for line in lines:\n",
    "        x0, y0, x1, y1, width = line\n",
    "        length = np.hypot(x1 - x0, y1 - y0)\n",
    "        if length >= min_length:\n",
    "            rr, cc = draw_line(int(y0), int(x0), int(y1), int(x1))\n",
    "            rr = np.clip(rr, 0, img_uint8.shape[0] - 1)\n",
    "            cc = np.clip(cc, 0, img_uint8.shape[1] - 1)\n",
    "            streaklet_mask[rr, cc] = True\n",
    "\n",
    "    # Morphological operations to clean up the mask\n",
    "    streaklet_mask = binary_dilation(streaklet_mask, footprint=disk(1))\n",
    "    streaklet_mask = remove_small_objects(streaklet_mask, min_size=50)\n",
    "\n",
    "    return streaklet_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796084f",
   "metadata": {},
   "source": [
    "Les images NEOSSat sont souvent prises en séquences qui permettent la détection d'objets en mouvement en comparant les changements à travers les trames. Vous pouvez détecter des objets en mouvement en calculant la différence entre des trames consécutives pour mettre en évidence les changements qui pourraient indiquer le mouvement d'objet.\n",
    "\n",
    "Voici un exemple de comment calculer la différence entre deux trames pour détecter le mouvement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_moving_objects(image_files, image_directory, image_shape):\n",
    "    num_images = len(image_files)\n",
    "    data_cube = np.zeros((num_images, *image_shape))\n",
    "\n",
    "    for idx, filename in enumerate(tqdm(image_files, desc='Loading images for moving object detection')):\n",
    "        filepath = os.path.join(image_directory, filename)\n",
    "        data_cube[idx] = read_fits_data(filepath)\n",
    "\n",
    "    # Calculate the median image to use as a reference (background)\n",
    "    median_image = np.median(data_cube, axis=0)\n",
    "\n",
    "    # Subtract the median image from each frame to detect changes\n",
    "    difference_cube = data_cube - median_image\n",
    "\n",
    "    # Apply threshold to detect significant changes\n",
    "    threshold = np.std(difference_cube) * 3  # Adjust the factor as needed\n",
    "    moving_objects_mask = np.max(difference_cube > threshold, axis=0)\n",
    "\n",
    "    # Clean up the mask\n",
    "    moving_objects_mask = binary_opening(moving_objects_mask, footprint=np.ones((3, 3)))\n",
    "    moving_objects_mask = remove_small_objects(moving_objects_mask, min_size=20)\n",
    "\n",
    "    return moving_objects_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90992f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect streaklets in individual images\n",
    "print('Detecting streaklets in individual images...')\n",
    "streaklet_masks = []\n",
    "for filename in tqdm(image_files, desc='Detecting streaklets'):\n",
    "    filepath = os.path.join(output_directory, filename)\n",
    "    data = read_fits_data(filepath)\n",
    "    streaklet_mask = detect_streaklets(data)\n",
    "    streaklet_masks.append(streaklet_mask)\n",
    "    # Save the streaklet mask\n",
    "    mask_filename = os.path.splitext(filename)[0] + '_streaklet_mask.fits'\n",
    "    mask_path = os.path.join(output_directory, mask_filename)\n",
    "    hdu = fits.PrimaryHDU(streaklet_mask.astype(np.uint8))\n",
    "    hdu.writeto(mask_path, overwrite=True)\n",
    "print('Streaklet detection completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect moving objects across images\n",
    "print('Detecting moving objects across images...')\n",
    "moving_objects_mask = detect_moving_objects(image_files, output_directory, image_shape)\n",
    "# Save the moving objects mask\n",
    "moving_objects_mask_path = os.path.join(output_directory, f'moving_objects_mask{image_type}.fits')\n",
    "hdu = fits.PrimaryHDU(moving_objects_mask.astype(np.uint8))\n",
    "hdu.writeto(moving_objects_mask_path, overwrite=True)\n",
    "print(f'Moving objects mask saved to {moving_objects_mask_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb3b9b",
   "metadata": {},
   "source": [
    "Cette technique peut être davantage améliorée en appliquant des filtres ou un seuillage pour réduire le bruit et mettre en évidence seulement les changements significatifs, aidant à isoler les objets en mouvement tels que les satellites ou astéroïdes.\n",
    "\n",
    "Une fois le mouvement détecté, la prochaine étape est de suivre l'objet à travers plusieurs trames. Les algorithmes de suivi d'objet, tels que le suivi de centroïde, peuvent être employés pour suivre le mouvement de l'objet détecté au fil du temps. En analysant la trajectoire et la vitesse, nous pouvons dériver des informations significatives sur le mouvement de l'objet.\n",
    "\n",
    "## Section E - Visualisation\n",
    "* Tracé de masques d'image\n",
    "* Création de visualisation GIF\n",
    "\n",
    "Dans cette section, nous visualisons les résultats de nos étapes de traitement. Vous verrez l'image empilée finale, ainsi que le masque de mouvement qui met en évidence le mouvement détecté à travers les trames. De plus, cette section fournit l'option de créer un GIF animé de l'objet en mouvement, vous permettant d'observer son mouvement au fil du temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab597db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(stacked_image, streaklet_masks, moving_objects_mask):\n",
    "    # Display the stacked image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    vmin, vmax = np.percentile(stacked_image, [5, 95])\n",
    "    plt.imshow(stacked_image, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    plt.title('Stacked Image')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Display the streaklets on a sample image\n",
    "    sample_idx = len(streaklet_masks) // 2\n",
    "    sample_mask = streaklet_masks[sample_idx]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(sample_mask, cmap='gray')\n",
    "    plt.title('Streaklet Mask (Sample Image)')\n",
    "    plt.show()\n",
    "\n",
    "    # Display the moving objects mask\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(moving_objects_mask, cmap='gray')\n",
    "    plt.title('Moving Objects Mask')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "visualize_results(stacked_image, streaklet_masks, moving_objects_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(image_files, image_directory, output_path, duration=0.5):\n",
    "    frames = []\n",
    "    for filename in tqdm(image_files, desc='Creating GIF'):\n",
    "        filepath = os.path.join(image_directory, filename)\n",
    "        data = read_fits_data(filepath)\n",
    "\n",
    "        # Normalize the image data for visualization\n",
    "        vmin, vmax = np.percentile(data, [5, 95])\n",
    "        normalized_data = np.clip((data - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "        # Convert to 8-bit grayscale image\n",
    "        image_8bit = (normalized_data * 255).astype(np.uint8)\n",
    "\n",
    "        # Append the image to the frames list\n",
    "        frames.append(image_8bit)\n",
    "\n",
    "    # Save the frames as an animated GIF and set loop to 0 for infinite looping\n",
    "    imageio.mimsave(output_path, frames, format='GIF', duration=duration, loop=0)\n",
    "    print(f\"Animated GIF saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b98c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the GIF\n",
    "gif_output_path = os.path.join(output_directory, 'animated_images.gif')\n",
    "\n",
    "# Create the GIF\n",
    "create_gif(image_files, output_directory, gif_output_path, duration=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2602f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the GIF\n",
    "Image(filename=gif_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdbef34",
   "metadata": {},
   "source": [
    "## Interprétation des Résultats\n",
    "\n",
    "À partir des images ci-dessus, nous pouvons voir qu'beaucoup de mouvement a été détecté entre les trames d'image. Ceci est en partie parce qu'aucune correction de dérive n'a été appliquée entre les piles d'images résultant en un décalage horizontal des objets. Cependant, pour notre objet d'intérêt, nous pouvons voir un mouvement diagonal entre les points. Le traitement du [\"flux optique\"](https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html) et la direction des vecteurs peut être une technique pour déterminer les objets d'intérêt.\n",
    "\n",
    "De plus, il est à noter que dans d'autres séries d'images, vous pourriez rencontrer de plus grandes striures. Celles-ci seront de grandes lignes à travers l'image et sont typiquement seulement visibles dans une seule trame. Elles représentent des objets à haute vitesse passant devant le capteur tels que des débris spatiaux ou des satellites proches.\n",
    "\n",
    "## Félicitations !\n",
    "\n",
    "Vous avez maintenant traité les données NEOSSat. C'est un ensemble de données complexe, avec de nombreuses façons de traitement. Donc, nous vous recommandons de continuer à explorer cet ensemble de données et de trouver de nouvelles façons excitantes de détecter et suivre les objets géocroiseurs.\n",
    "\n",
    "L'ensemble de données NEOSSat peut aussi être utilisé pour créer d'autres produits de données précieux, tels que des diagrammes de courbe de lumière. Ces diagrammes sont cruciaux pour la détection et l'analyse d'exoplanètes, car ils suivent les variations de la luminosité d'une étoile au fil du temps, aidant à identifier les transits d'exoplanètes potentiels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}